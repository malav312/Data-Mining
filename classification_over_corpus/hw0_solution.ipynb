{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"AqAdR0KxvEb6","outputId":"d1617c16-611e-4b5f-e88e-bdfe95efbb8a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["\n","\n","# mount your Google Drive, so that you can read data from it.\n","# Note: it needs your authorization.\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3em67LDcw0xm"},"outputs":[],"source":["import numpy as np\n","import random\n","from tqdm import tqdm\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"5P87-_qUv15D"},"source":["**Utility Functions**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85},"id":"i3Gprf3UxHca","outputId":"8926a010-764e-47cf-f2eb-87d82c6056ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["import string\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import *\n","\n","# stemming tool from nltk\n","stemmer = PorterStemmer()\n","# a mapping dictionary that help remove punctuations\n","remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n","\n","def get_tokens(text):\n","    # turn document into lowercase\n","    lowers = text.lower()\n","    # remove punctuation\n","    no_punctuation = lowers.translate(remove_punctuation_map)\n","    # tokenize document\n","    tokens = nltk.word_tokenize(no_punctuation)\n","    # stop words\n","    filtered = [w for w in tokens if not w in stopwords.words(\"english\")]\n","    # stemming process\n","    stemmed = []\n","    for item in filtered:\n","        stemmed.append(stemmer.stem(item))\n","\n","    return stemmed\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0pIr5wUHv1Ft"},"outputs":[],"source":["import numpy as np\n","\n","\n","def get_dict(fpath):\n","    dictionary = {}\n","\n","\n","    with open(fpath, \"r\") as f:\n","        for i, word in enumerate(f):\n","            dictionary[word.strip()] = i\n","\n","    return dictionary\n","\n","\n","def get_doc_tf(word_set, dictionary):\n","    n_words = len(dictionary)\n","    tf_vec = np.zeros(n_words)\n","\n","    max_cnt = 0\n","    for word in word_set:\n","        idx = dictionary[word]\n","        tf_vec[idx] += 1.0\n","\n","        if tf_vec[idx] > max_cnt:\n","            max_cnt = tf_vec[idx]\n","\n","    return tf_vec / max_cnt\n","\n","\n","\n","def get_tf_idf(tf_dict, df_vec, n_doc, n_words):\n","\n","    tf_idf_mtx = np.zeros((n_doc, n_words))\n","    idf = np.log(n_doc / df_vec)\n","\n","    for doc_idx, tf_vec in tf_dict.items():\n","        tf_idf = tf_dict[doc_idx]*idf\n","\n","        tf_idf_mtx[doc_idx, :] = tf_idf\n","\n","    return tf_idf_mtx\n","\n","\n","def write(d, fpath):\n","\n","    with open(fpath, \"w\") as f:\n","\n","        for k, v in d.items():\n","\n","            f.write(f\"{k}\\n\")\n","\n","\n","def filter_top_k(counter_sorted, limit):\n","    top_k = {}\n","\n","    for i, k in enumerate(counter_sorted.keys()):\n","        if i == limit:\n","            break\n","        top_k[k] = counter_sorted[k]\n","\n","    return top_k"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dULOD0g4w_K7"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hs3bXkN-v9rj"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ji2l2dV0v_UN"},"source":["**Compute TF-IDF Matrix**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6rhOh0MTwCSL"},"outputs":[],"source":["def tfidf_main(fpath, dictionary):\n","\n","\n","    n_words = len(dictionary)\n","    tf = {}\n","    doc_freq = np.zeros(n_words)\n","\n","    with open(fpath, 'r') as f:\n","\n","        lines = f.readlines()\n","        n_doc = len(lines) - 1\n","\n","        for i, line in tqdm(enumerate(lines), total=n_doc+1):\n","            if i == 0:\n","                continue\n","\n","            doc_idx = i - 1\n","\n","            id, txt, cat = line.split(\",\")\n","            cat = cat.strip()\n","            tokens = get_tokens(txt)\n","\n","            filtered = []\n","            filtered_unique = set()\n","            for word in tokens:\n","                if word in dictionary:\n","                    filtered.append(word)\n","                    filtered_unique.add(word)\n","\n","            # get term frequency\n","            tf_vec = get_doc_tf(filtered, dictionary)\n","            tf[doc_idx] = tf_vec\n","\n","            # get doc frequency:\n","            for word in filtered_unique:\n","                idx = dictionary[word]\n","                doc_freq[idx] += 1\n","\n","\n","    tfidf_mtx = get_tf_idf(tf, doc_freq, n_doc, n_words)\n","\n","\n","    return tfidf_mtx"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"Tv1Irp_CwfNf","outputId":"8add237c-ef13-4096-a8b7-debdeb8240f5"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1491/1491 [01:08<00:00, 21.83it/s]\n"]}],"source":["dictionary = get_dict(\"/content/drive/My Drive/Colab Notebooks/dictionary.txt\")\n","tfidf = tfidf_main(\"/content/drive/My Drive/Colab Notebooks/news-train.csv\", dictionary)\n","np.savetxt(\"/content/drive/My Drive/Colab Notebooks/tfidf.txt\", tfidf,  fmt='%.4f', delimiter=\",\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":243},"id":"bnvmUiD2wvQ3","outputId":"21f10225-7b67-4590-b71d-e56ea07da379"},"outputs":[{"data":{"text/plain":["array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n","        0.        ],\n","       [0.        , 0.        , 0.36351873, ..., 0.        , 0.        ,\n","        0.        ],\n","       [0.12511637, 0.        , 0.        , ..., 0.        , 0.        ,\n","        0.        ],\n","       ...,\n","       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n","        0.        ],\n","       [0.        , 0.        , 0.2796298 , ..., 0.20404393, 0.        ,\n","        0.        ],\n","       [0.2144852 , 0.36719042, 0.        , ..., 0.        , 0.        ,\n","        0.        ]])"]},"execution_count":40,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["tfidf"]},{"cell_type":"markdown","metadata":{"id":"-Mumh_5yycEs"},"source":["**Word Frequencies**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cHR2MTx8yhM_"},"outputs":[],"source":["def frequency_main(limit, fpath, dictionary):\n","\n","\n","\n","    with open(fpath, 'r') as f:\n","\n","        lines = f.readlines()\n","        n_doc = len(lines) - 1\n","\n","        stratifed_cntr = {\n","                        \"sport\": {},\n","                        \"business\": {},\n","                        \"politics\": {},\n","                        \"entertainment\": {},\n","                        \"tech\": {}\n","                    }\n","\n","\n","        for i, line in tqdm(enumerate(lines), total=n_doc + 1):\n","            if i == 0:\n","                continue\n","\n","            id, txt, cat = line.split(\",\")\n","            cat = cat.strip()\n","            tokens = get_tokens(txt)\n","\n","            for t in tokens:\n","                if t not in dictionary:\n","                    continue\n","\n","                if t not in stratifed_cntr[cat]:\n","                    stratifed_cntr[cat][t] = 0\n","\n","                stratifed_cntr[cat][t] += 1\n","\n","        stratifed_sorted = {}\n","        for cat, cnts in stratifed_cntr.items():\n","            stratifed_sorted[cat] = {k: v for k, v in sorted(cnts.items(), key=lambda item: item[1], reverse=True)}\n","\n","\n","        stratified_output = {}\n","        for cat, cnts in stratifed_sorted.items():\n","            stratified_output[cat] = filter_top_k(cnts, limit)\n","\n","    return stratified_output"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"86FV4sAyyjpQ","outputId":"e58983a7-f7b2-4f39-e3b9-566e29cae36b"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1491/1491 [01:14<00:00, 20.15it/s]\n"]}],"source":["counts = frequency_main(limit=3, fpath=\"/content/drive/My Drive/Colab Notebooks/news-train.csv\", dictionary=dictionary)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":102},"id":"MxfDIYyTy0V2","outputId":"99bca961-d4d3-462f-b952-1612a7f59c8d"},"outputs":[{"data":{"text/plain":["{'business': {'said': 1100, 'us': 511, 'year': 574},\n"," 'entertainment': {'best': 404, 'film': 706, 'said': 594},\n"," 'politics': {'mr': 1100, 'said': 1445, 'would': 710},\n"," 'sport': {'game': 482, 'said': 635, 'win': 419},\n"," 'tech': {'peopl': 646, 'said': 1064, 'use': 662}}"]},"execution_count":21,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["counts"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SThdIktVy019"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"WzpTQ-xFzcsV"},"source":["**Average TFIDF Scores by Category**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gFuOaMlHzgwm"},"outputs":[],"source":["def mean_tfidf_main(trn_fpath, tfidf_fpath, dictionary, k):\n","\n","    idx_to_word = {}\n","    for key, val in dictionary.items():\n","        idx_to_word[val] = key\n","\n","    with open(trn_fpath, 'r') as f:\n","\n","        lines = f.readlines()\n","        n_doc = len(lines) - 1\n","        cats = np.zeros((n_doc, 1), dtype=object)\n","\n","        for i, line in tqdm(enumerate(lines), total=n_doc + 1):\n","            if i == 0:\n","                continue\n","\n","            doc_idx = i - 1\n","            id, txt, cat = line.split(\",\")\n","            cat = cat.strip()\n","\n","            cats[doc_idx, 0] = cat\n","\n","        tfidf = np.loadtxt(tfidf_fpath, delimiter=\",\")\n","\n","        df = pd.DataFrame(np.concatenate([cats, tfidf], axis=1))\n","\n","        groups = df.groupby(0)\n","\n","        output = {}\n","\n","        for cat, chunk in groups:\n","\n","            mean = chunk.values[:, 1:].mean(axis=0)\n","\n","            word_idx = np.argsort(mean)\n","            s = np.sort(mean)\n","            top_k = word_idx[-k:]\n","\n","            output[cat] = {}\n","            for idx in top_k:\n","                word = idx_to_word[idx]\n","                score = mean[idx]\n","                #record = {\"word\": word, \"score\": score}\n","                output[cat][word] = score\n","\n","\n","    return output"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"miLT3C-BzlKf","outputId":"2abbf891-840d-437e-c10f-7743d38ddabb"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1491/1491 [00:00<00:00, 340189.70it/s]\n"]}],"source":["avg_tfidf = mean_tfidf_main(\"/content/drive/My Drive/Colab Notebooks/news-train.csv\", \"/content/drive/My Drive/Colab Notebooks/tfidf.txt\", dictionary, k=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":272},"id":"EoHFmEmEzzA0","outputId":"9e2fa578-3bda-4969-f644-45d4de4ca617"},"outputs":[{"data":{"text/plain":["{'business': {'bank': 0.27173065476190483,\n","  'compani': 0.26359047619047643,\n","  'firm': 0.28594910714285693},\n"," 'entertainment': {'award': 0.3742216117216118,\n","  'film': 0.6771014652014654,\n","  'star': 0.37003956043956027},\n"," 'politics': {'elect': 0.42791788321167834,\n","  'labour': 0.44298394160583926,\n","  'mr': 0.43852372262773653},\n"," 'sport': {'england': 0.2966031791907518,\n","  'game': 0.34770780346820834,\n","  'win': 0.31158150289017345},\n"," 'tech': {'mobil': 0.3374674329501916,\n","  'softwar': 0.31584597701149414,\n","  'technolog': 0.3140869731800769}}"]},"execution_count":30,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["avg_tfidf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4aWRudlfz3Og"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"nbformat":4,"nbformat_minor":0}