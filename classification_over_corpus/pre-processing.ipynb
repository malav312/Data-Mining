{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"3em67LDcw0xm"},"outputs":[],"source":["import numpy as np\n","import random\n","from tqdm import tqdm\n","import pandas as pd"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85},"id":"i3Gprf3UxHca","outputId":"8926a010-764e-47cf-f2eb-87d82c6056ac"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /home/malav312/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to\n","[nltk_data]     /home/malav312/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["# tokens punctuations, stopwords and stemming\n","#can use n-gram, tf-idf, word2vec, doc2vec an\n","import string\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import *\n","\n","# stemming tool from nltk\n","stemmer = PorterStemmer()\n","# a mapping dictionary that help remove punctuations\n","remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n","\n","def get_tokens(text):\n","    # turn document into lowercase\n","    lowers = text.lower()\n","    # remove punctuation\n","    no_punctuation = lowers.translate(remove_punctuation_map)\n","    # tokenize document\n","    tokens = nltk.word_tokenize(no_punctuation)\n","    # stop words\n","    filtered = [w for w in tokens if not w in stopwords.words(\"english\")]\n","    # stemming process\n","    stemmed = []\n","    for item in filtered:\n","        stemmed.append(stemmer.stem(item))\n","\n","    return stemmed\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"0pIr5wUHv1Ft"},"outputs":[],"source":["import numpy as np\n","\n","\n","def get_dict(fpath):\n","    dictionary = {}\n","\n","\n","    with open(fpath, \"r\") as f:\n","        for i, word in enumerate(f):\n","            dictionary[word.strip()] = i\n","\n","    return dictionary\n","\n","\n","def get_doc_tf(word_set, dictionary):\n","    n_words = len(dictionary)\n","    tf_vec = np.zeros(n_words)\n","\n","    max_cnt = 0\n","    for word in word_set:\n","        idx = dictionary[word]\n","        tf_vec[idx] += 1.0\n","\n","        if tf_vec[idx] > max_cnt:\n","            max_cnt = tf_vec[idx]\n","\n","    return tf_vec / max_cnt\n","\n","\n","\n","def get_tf_idf(tf_dict, df_vec, n_doc, n_words):\n","\n","    tf_idf_mtx = np.zeros((n_doc, n_words))\n","    idf = np.log(n_doc / df_vec)\n","\n","    for doc_idx, tf_vec in tf_dict.items():\n","        tf_idf = tf_dict[doc_idx]*idf\n","\n","        tf_idf_mtx[doc_idx, :] = tf_idf\n","\n","    return tf_idf_mtx\n","\n","\n","def write(d, fpath):\n","\n","    with open(fpath, \"w\") as f:\n","\n","        for k, v in d.items():\n","\n","            f.write(f\"{k}\\n\")\n","\n","\n","def filter_top_k(counter_sorted, limit):\n","    top_k = {}\n","\n","    for i, k in enumerate(counter_sorted.keys()):\n","        if i == limit:\n","            bre\n","        top_k[k] = counter_sorted[k]\n","\n","    return top_k"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
